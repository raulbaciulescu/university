{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Salut, sunt Raul!\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' Salut, Raul! Sunt un AI. Sunt bucuros sa te cunosc. Ce pot sa fac pentru tine?'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import ConversationChain\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = OpenAI(model_name='text-davinci-003',\n",
    "             temperature=0,\n",
    "             max_tokens=256)\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "conversation.predict(input=\"Salut, sunt Raul!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Salut, sunt Raul!\n",
      "AI:  Salut, Raul! Sunt un AI. Sunt bucuros sa te cunosc. Ce pot sa fac pentru tine?\n",
      "Human: Cum esti astazi?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' Astazi sunt foarte bine! Am avut o zi plina de activitati interesante si am invatat multe lucruri noi. Tu cum a fost ziua ta?'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Cum esti astazi?\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Salut, sunt Raul!\n",
      "AI:  Salut, Raul! Sunt un AI. Sunt bucuros sa te cunosc. Ce pot sa fac pentru tine?\n",
      "Human: Cum esti astazi?\n",
      "AI:  Astazi sunt foarte bine! Am avut o zi plina de activitati interesante si am invatat multe lucruri noi. Tu cum a fost ziua ta?\n",
      "Human: Sunt bine. Poti sa ma ajuti cu ceva?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' Desigur! Ce anume pot sa fac pentru tine?'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Sunt bine. Poti sa ma ajuti cu ceva?\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Salut, sunt Raul!\n",
      "AI:  Salut, Raul! Sunt un AI. Sunt bucuros sa te cunosc. Ce pot sa fac pentru tine?\n",
      "Human: Cum esti astazi?\n",
      "AI:  Astazi sunt foarte bine! Am avut o zi plina de activitati interesante si am invatat multe lucruri noi. Tu cum a fost ziua ta?\n",
      "Human: Sunt bine. Poti sa ma ajuti cu ceva?\n",
      "AI:  Desigur! Ce anume pot sa fac pentru tine?\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.buffer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Salut, sunt Raul!\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' Salut, Raul! Sunt un AI. Sunt bucuros sa te cunosc. Ce pot sa fac pentru tine?'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain import ConversationChain\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm = OpenAI(model_name='text-davinci-003',\n",
    "             temperature=0,\n",
    "             max_tokens=256)\n",
    "summary_memory = ConversationSummaryMemory(llm=OpenAI())\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=summary_memory\n",
    ")\n",
    "\n",
    "conversation.predict(input=\"Salut, sunt Raul!\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "The human introduces himself as Raul and the AI greets him and expresses its pleasure in getting to know him, asking how it can help.\n",
      "Human: Cum esti astazi?\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' Salut, Raul! Sunt bine, mulțumesc. Sunt bucuros să te cunosc. Cum pot să te ajut?'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Cum esti astazi?\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conversation.predict(input=\"Sunt bine. Poti sa ma ajuti cu ceva?\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there! I am Raul\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "\" Hi Raul! It's nice to meet you. My name is AI. What can I do for you today?\""
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryMemory, ConversationBufferWindowMemory\n",
    "from langchain import ConversationChain\n",
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "\n",
    "llm = OpenAI(model_name='text-davinci-003',\n",
    "             temperature=0,\n",
    "             max_tokens=256)\n",
    "summary_memory = ConversationBufferWindowMemory(k=2)  # tine minte ultimele asa cum sunt ele, fara rezumat\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=summary_memory\n",
    ")\n",
    "\n",
    "conversation.predict(input=\"Hi there! I am Raul\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there! I am Raul\n",
      "AI:  Hi Raul! It's nice to meet you. My name is AI. What can I do for you today?\n",
      "Human: I am looking for some customer support\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' Sure thing! I can help you with that. What kind of customer support do you need?'"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"I am looking for some customer support\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there! I am Raul\n",
      "AI:  Hi Raul! It's nice to meet you. My name is AI. What can I do for you today?\n",
      "Human: I am looking for some customer support\n",
      "AI:  Sure thing! I can help you with that. What kind of customer support do you need?\n",
      "Human: My TV is not working.\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "\" I'm sorry to hear that. Can you tell me a bit more about the issue you're having with your TV?\""
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"My TV is not working.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: I am looking for some customer support\n",
      "AI:  Sure thing! I can help you with that. What kind of customer support do you need?\n",
      "Human: My TV is not working.\n",
      "AI:  I'm sorry to hear that. Can you tell me a bit more about the issue you're having with your TV?\n",
      "Human: When I turn it on it makes some weird sounds and then goes black\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "\" That doesn't sound good. Have you tried unplugging the TV and plugging it back in? That can sometimes help reset the system.\""
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"When I turn it on it makes some weird sounds and then goes black\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Hi there! I am Raul', additional_kwargs={}), AIMessage(content=\" Hi Raul! It's nice to meet you. My name is AI. What can I do for you today?\", additional_kwargs={}), HumanMessage(content='I am looking for some customer support', additional_kwargs={}), AIMessage(content=' Sure thing! I can help you with that. What kind of customer support do you need?', additional_kwargs={}), HumanMessage(content='My TV is not working.', additional_kwargs={}), AIMessage(content=\" I'm sorry to hear that. Can you tell me a bit more about the issue you're having with your TV?\", additional_kwargs={}), HumanMessage(content='When I turn it on it makes some weird sounds and then goes black', additional_kwargs={}), AIMessage(content=\" That doesn't sound good. Have you tried unplugging the TV and plugging it back in? That can sometimes help reset the system.\", additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "print(conversation.memory.buffer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Basic Conversation with ConversationSummaryBufferMemory\n",
    "\"It keeps a buffer of recent interactions in memory, but rather than just completely flushing old interactions it compiles them into a summary and uses both\"\n",
    "Tine minte in buffer ultimele interactiuni pana cand trece de limita de tokenuri, apoi face rezumat, deci sunt folosite ambele variante"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there! I am Raul\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "\" Hi Raul! It's nice to meet you. My name is AI. What can I do for you today?\""
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.conversation.memory import ConversationSummaryBufferMemory\n",
    "from langchain import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm = OpenAI(model_name='text-davinci-003',\n",
    "             temperature=0,\n",
    "             max_tokens=512)\n",
    "# Setting k=2, will only keep the last 2 interactions in memory\n",
    "# max_token_limit=40 - token limits needs transformers installed\n",
    "memory = ConversationSummaryBufferMemory(llm=OpenAI(), max_token_limit=10)\n",
    "\n",
    "conversation_with_summary = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "conversation_with_summary.predict(input=\"Hi there! I am Raul\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: \n",
      "The human, Raul, introduces themselves to the AI, who introduces itself and asks what it can do for Raul.\n",
      "Human: I need help with my broken TV\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "\" Hi Raul, I'm AI. It's nice to meet you. I'm sorry to hear that your TV is broken. What seems to be the problem?\""
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"I need help with my broken TV\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: \n",
      "Raul introduced himself to the AI, who introduced itself and asked what it could do for Raul. Raul mentioned that he needed help with his broken TV, to which the AI apologized and asked what the problem was.\n",
      "Human: It makes weird sounds when i turn it on and then goes black\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "\" I'm sorry to hear that. It sounds like you may have a hardware issue with your TV. Can you tell me what kind of TV it is and what model it is?\""
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"It makes weird sounds when i turn it on and then goes black\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: \n",
      "The human introduces themselves as Raul and the AI introduces itself as AI and asks what it can do for Raul.\n",
      "Human: I need help with my broken TV\n",
      "AI:  Sure, I'd be happy to help. Can you tell me a bit more about the issue? What kind of TV do you have and what is the problem?\n",
      "Human: It makes weird sounds when i turn it on and then goes black\n",
      "AI:  Hmm, that doesn't sound good. It sounds like you may have a hardware issue. Have you tried resetting the TV or checking the connections?\n",
      "Human: Led\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "\" I see. You have an LED TV. That's great. Have you tried resetting the TV or checking the connections?\""
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"Led\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: \n",
      "The human introduces themselves as Raul and the AI introduces itself as AI and asks what it can do for Raul. Raul states he needs help with his broken TV and AI offers to help, asking for more details about the issue.\n",
      "Human: It makes weird sounds when i turn it on and then goes black\n",
      "AI:  Hmm, that doesn't sound good. It sounds like you may have a hardware issue. Have you tried resetting the TV or checking the connections?\n",
      "Human: Led\n",
      "AI:  I see. You have an LED TV. That's great. Have you tried resetting the TV or checking the connections?\n",
      "Human: I will try\n",
      "AI:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "'  Great! Let me know if you need any help with that. In the meantime, is there anything else I can help you with?'"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"I will try\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The human introduces themself as Raul and the AI responds, introducing itself as AI. The human has asked the AI for help with their broken TV, and the AI has agreed and asked for more information about the issue. The human explains that the TV makes weird sounds when it is turned on and then goes black, and the AI suggests that this is likely a hardware issue and asks the human if the TV is an LCD or an LED. The human confirms it is an LED and the AI suggests unplugging the TV and plugging it back in. The human agrees to try this.\n"
     ]
    }
   ],
   "source": [
    "print(conversation_with_summary.memory.moving_summary_buffer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{'Maria': '', 'Cluj': ''}\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Last line:\n",
      "Human: Salut, sunt Maria si vreau sa stiu cum va fi vremea in 3 zile in Cluj\n",
      "You:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' Salut Maria! Vremea in Cluj in urmatoarele 3 zile va fi destul de calda, cu temperaturi medii de aproximativ 20 de grade Celsius. Va fi insorit, cu putine nori si ploi slabe.'"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import OpenAI, ConversationChain\n",
    "from langchain.chains.conversation.memory import ConversationEntityMemory\n",
    "from langchain.chains.conversation.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Dict, Any\n",
    "from pprint import pprint\n",
    "\n",
    "## The prompt\n",
    "ENTITY_MEMORY_CONVERSATION_TEMPLATE.template\n",
    "\n",
    "llm = OpenAI(model_name='text-davinci-003',\n",
    "             temperature=0,\n",
    "             max_tokens=256)\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "    memory=ConversationEntityMemory(llm=llm)\n",
    ")\n",
    "\n",
    "conversation.predict(input=\"Salut, sunt Maria si vreau sa stiu cum va fi vremea in 3 zile in Cluj\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{'Cluj': 'Cluj va avea temperaturi medii de aproximativ 20 de grade Celsius in urmatoarele 3 zile, cu soare si putine nori si ploi slabe.'}\n",
      "\n",
      "Current conversation:\n",
      "Human: Salut, sunt Maria si vreau sa stiu cum va fi vremea in 3 zile in Cluj\n",
      "AI:  Salut Maria! Vremea in Cluj in urmatoarele 3 zile va fi destul de calda, cu temperaturi medii de aproximativ 20 de grade Celsius. Va fi insorit, cu putine nori si ploi slabe.\n",
      "Last line:\n",
      "Human: Ce activitati imi recomanzi sa fac afara?\n",
      "You:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' Salut Maria! In functie de preferintele tale, iti recomand sa faci o plimbare in aer liber, sa te bucuri de natura, sa faci o plimbare cu bicicleta sau sa te bucuri de un picnic in parc.'"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Ce activitati imi recomanzi sa fac afara?\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cluj': 'Cluj va avea temperaturi medii de aproximativ 20 de grade Celsius in '\n",
      "         'urmatoarele 3 zile, cu soare si putine nori si ploi slabe. '\n",
      "         'Activitati recomandate in aer liber includ plimbari, bucuria '\n",
      "         'naturii, plimbari cu bicicleta si picnicuri in parc.',\n",
      " 'Maria': 'Maria este o persoana din Cluj care a intrebat despre vremea din '\n",
      "          'urmatoarele 3 zile.'}\n"
     ]
    }
   ],
   "source": [
    "conversation.memory.entity_cache\n",
    "pprint(conversation.memory.store)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new ConversationChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
      "\n",
      "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
      "\n",
      "Context:\n",
      "{'Cluj': 'Cluj va avea temperaturi medii de aproximativ 20 de grade Celsius in urmatoarele 3 zile, cu soare si putine nori si ploi slabe. Activitati recomandate in aer liber includ plimbari, bucuria naturii, plimbari cu bicicleta si picnicuri in parc.'}\n",
      "\n",
      "Current conversation:\n",
      "Human: Salut, sunt Maria si vreau sa stiu cum va fi vremea in 3 zile in Cluj\n",
      "AI:  Salut Maria! Vremea in Cluj in urmatoarele 3 zile va fi destul de calda, cu temperaturi medii de aproximativ 20 de grade Celsius. Va fi insorit, cu putine nori si ploi slabe.\n",
      "Human: Ce activitati imi recomanzi sa fac afara?\n",
      "AI:  Salut Maria! In functie de preferintele tale, iti recomand sa faci o plimbare in aer liber, sa te bucuri de natura, sa faci o plimbare cu bicicleta sau sa te bucuri de un picnic in parc.\n",
      "Last line:\n",
      "Human: Nu-mi place bicicleta, pot pescui?\n",
      "You:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "' Salut Maria! Desi nu recomandam pescuitul in parcuri, exista multe locuri in Cluj unde poti pescui. Te sfatuim sa verifici regulile si restrictiile locale inainte de a incepe sa pescuiesti.'"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Nu-mi place bicicleta, pot pescui?\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cluj': 'Cluj va avea temperaturi medii de aproximativ 20 de grade Celsius in '\n",
      "         'urmatoarele 3 zile, cu soare si putine nori si ploi slabe. '\n",
      "         'Activitati recomandate in aer liber includ plimbari, bucuria '\n",
      "         'naturii, plimbari cu bicicleta si picnicuri in parc. Exista, de '\n",
      "         'asemenea, multe locuri in Cluj unde poti pescui, insa te sfatuim sa '\n",
      "         'verifici regulile si restrictiile locale inainte de a incepe sa '\n",
      "         'pescuiesti.',\n",
      " 'Maria': 'Maria este o persoana din Cluj care a intrebat despre vremea din '\n",
      "          'urmatoarele 3 zile.'}\n"
     ]
    }
   ],
   "source": [
    "conversation.memory.entity_cache\n",
    "pprint(conversation.memory.store)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A512453': 'A512453 is a warranty number for a broken TV.',\n",
      " 'Dave': 'Dave is a repair person who can be sent to fix the broken TV.',\n",
      " 'Sam': 'Sam is the owner of a TV that is currently broken but under warranty.',\n",
      " 'TV': 'TV is broken but under warranty.'}\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
