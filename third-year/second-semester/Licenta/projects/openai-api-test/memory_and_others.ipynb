{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "os.environ['SERPAPI_API_KEY'] = '08e4eaeeea03650a06bc8e3572e0982af4e6bc1b9f5d440a2e596b51a14b495a'\n",
    "llm = OpenAI(temperature=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.schema import messages_from_dict, messages_to_dict\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "history.add_user_message(\"hi!\")\n",
    "history.add_ai_message(\"whats up?\")\n",
    "dicts = messages_to_dict(history.messages)\n",
    "new_messages = messages_from_dict(dicts)\n",
    "new_messages"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-12T22:55:20.852068Z",
     "end_time": "2023-04-12T22:55:20.871885Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=10)\n",
    "memory.save_context({\"input\": \"hi\"}, {\"ouput\": \"whats up\"})\n",
    "memory.save_context({\"input\": \"not much you\"}, {\"ouput\": \"not much\"})\n",
    "memory.save_context({\"input\": \"I have a question regarding my arduino\"}, {\"ouput\": \"What is your question?\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T16:03:47.804301Z",
     "end_time": "2023-04-03T16:03:49.362539Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain import ConversationChain\n",
    "\n",
    "def count_tokens(chain, query):\n",
    "    with get_openai_callback() as cb:\n",
    "        result = chain.run(query)\n",
    "        print(f'Spent a total of {cb.total_tokens} tokens')\n",
    "\n",
    "    return result\n",
    "\n",
    "conversation_sum = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=ConversationSummaryBufferMemory(llm=llm, max_token_limit=10)\n",
    ")\n",
    "\n",
    "count_tokens(\n",
    "    conversation_sum,\n",
    "    \"Salut AI!\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T16:28:22.425589Z",
     "end_time": "2023-04-03T16:28:24.622770Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "count_tokens(\n",
    "    conversation_sum,\n",
    "    \"Vreau sa stiu mai multe despre inflatie\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T16:29:22.641318Z",
     "end_time": "2023-04-03T16:29:28.681886Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "llm = OpenAI(model_name='text-davinci-003',\n",
    "             temperature=0,\n",
    "             max_tokens=512)\n",
    "# Setting k=2, will only keep the last 2 interactions in memory\n",
    "# max_token_limit=40 - token limits needs transformers installed\n",
    "memory = ConversationSummaryBufferMemory(llm=OpenAI(), max_token_limit=10)\n",
    "\n",
    "conversation_with_summary = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "result = conversation_with_summary.predict(input=\"Salut sunt Raul\")\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T16:39:28.895930Z",
     "end_time": "2023-04-03T16:39:31.530960Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "count_tokens(conversation_with_summary, \"ce este rata de refresh a unui laptop?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T16:42:19.764849Z",
     "end_time": "2023-04-03T16:42:23.804364Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conversation_with_summary.predict(input=\"rata de refresh apartine procesorului sau placii video?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T16:43:17.801281Z",
     "end_time": "2023-04-03T16:43:21.210375Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conversation_with_summary.predict(input=\"ce e display panel? in romana te rog\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T16:43:46.633069Z",
     "end_time": "2023-04-03T16:43:51.328824Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conversation_with_summary.predict(input=\"ce te-am intrebat inainte?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T16:44:19.025071Z",
     "end_time": "2023-04-03T16:44:22.651273Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conversation_with_summary.predict(input=\"despre ce vorbeam inainte?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T16:44:32.544541Z",
     "end_time": "2023-04-03T16:44:37.502063Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conversation_with_summary.predict(input=\"daca am un monitor cu o rata de refresh mare dar un laptop cu o placa video prea slaba cum va fi comportamentul?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-03T16:45:44.143610Z",
     "end_time": "2023-04-03T16:45:50.369247Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
